# CoT-DFA: Chain-of-Thought Dataflow Analysis

> **MATS 10.0 Application Project for Neel Nanda**  
> Applying Compiler Reaching Definitions to Detect Unfaithful Reasoning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  "Can we tell when a CoT was causally important for giving its answer?"    â”‚
â”‚                                        â€” Neel Nanda, MATS 10.0 Interests   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Executive Summary

**Problem**: How do we know if a model's Chain-of-Thought reasoning actually 
influenced its answer, or if it's post-hoc rationalization?

**Approach**: Apply **reaching definitions** â€” a classical compiler dataflow 
analysis â€” to CoT traces. This detects:
- **Phantom Code**: Elements appearing in output without CoT justification
- **Dead Reasoning**: CoT steps that don't contribute to any output

**Key Insight**: Treat CoT as a program trace where each reasoning step 
"defines" concepts that should "reach" the final output.

**Target Domain**: Code generation models (output is verifiable via execution)

---

## Table of Contents

1. [Research Question & Hypothesis](#1-research-question--hypothesis)
2. [Background: Reaching Definitions](#2-background-reaching-definitions)
3. [Architecture Overview](#3-architecture-overview)
4. [Formal Definitions](#4-formal-definitions)
5. [Metrics](#5-metrics)
6. [Implementation Plan](#6-implementation-plan)
7. [Alignment with Neel's Interests](#7-alignment-with-neels-interests)
8. [Extension: Circuit Provenance Bridge](#8-extension-circuit-provenance-bridge)
9. [Compute & Timeline](#9-compute--timeline)
10. [Expected Results](#10-expected-results)

---

## 1. Research Question & Hypothesis

### Primary Research Question

> **Can compiler-style reaching definitions analysis detect unfaithful 
> Chain-of-Thought in code generation models?**

### Hypothesis (Pass/Fail)

```
Hâ‚: phantom_ratio (code elements without CoT justification) 
    correlates with test case failure rate.

    High phantoms â†’ Model generated code without reasoning it through
                 â†’ Higher probability of bugs

Hâ‚€: No correlation (phantom_ratio independent of correctness)
```

### Secondary Hypotheses

```
Hâ‚‚: dead_ratio (CoT steps not reaching code) > 0.3 indicates 
    "padding" behavior â€” model generating filler reasoning

Hâ‚ƒ: Models produce MORE phantoms on harder problems 
    (taking shortcuts under difficulty)

Hâ‚„: Correlation between phantom locations and actual bug locations
```

---

## 2. Background: Reaching Definitions

### Classical Compiler Definition

In program analysis, **reaching definitions** answers:

> "For each use of variable x, which definitions of x could have 
> produced the value?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Traditional Program Analysis                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚    d1: x = 5          â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚    d2: y = x + 1            â”‚ d1 reaches this use           â”‚
â”‚    d3: x = 10         â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚    d4: z = x + y            â”‚      â”‚ d3 reaches, d1 killed  â”‚
â”‚                             â–¼      â–¼                        â”‚
â”‚                                                              â”‚
â”‚    At d2: RD(x) = {d1}                                      â”‚
â”‚    At d4: RD(x) = {d3}, RD(y) = {d2}                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CoT-DFA Mapping

| Program Analysis      | CoT-DFA Equivalent                        |
|-----------------------|-------------------------------------------|
| Variable definition   | CoT step introducing concept/approach     |
| Variable use          | Code element using that concept           |
| Reaching definition   | Which CoT step justifies this code?       |
| Dead code             | CoT steps not reaching any output         |
| Use without def       | **PHANTOM** â€” code without reasoning      |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CoT-DFA Analysis                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  CoT Trace:                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ s1: "First, I'll use a hash map for O(1) lookup"    â”‚   â”‚
â”‚  â”‚ s2: "I need to handle the edge case of empty input" â”‚   â”‚
â”‚  â”‚ s3: "Let me add some comments for clarity"          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                    â”‚                           â”‚
â”‚            â–¼                    â–¼                           â”‚
â”‚  Code Output:                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ def solve(nums):                                     â”‚   â”‚
â”‚  â”‚     seen = {}  â—„â”€â”€â”€ s1 reaches (hash map)           â”‚   â”‚
â”‚  â”‚     if not nums:  â—„â”€â”€â”€ s2 reaches (edge case)       â”‚   â”‚
â”‚  â”‚         return -1                                    â”‚   â”‚
â”‚  â”‚     for n in nums:                                   â”‚   â”‚
â”‚  â”‚         seen[n] = True                               â”‚   â”‚
â”‚  â”‚     return max(seen.keys()) â—„â”€â”€â”€ PHANTOM! (no CoT)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  Analysis:                                                   â”‚
â”‚  â€¢ s1 â†’ LIVE (reaches hash map usage)                       â”‚
â”‚  â€¢ s2 â†’ LIVE (reaches edge case check)                      â”‚
â”‚  â€¢ s3 â†’ DEAD (no code element matches "comments")           â”‚
â”‚  â€¢ max(seen.keys()) â†’ PHANTOM (not discussed in CoT)        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Architecture Overview

### High-Level Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CoT-DFA PIPELINE                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  INPUT   â”‚      â”‚  PARSE   â”‚      â”‚ ANALYZE  â”‚      â”‚  OUTPUT  â”‚
     â”‚          â”‚ â”€â”€â”€â–º â”‚          â”‚ â”€â”€â”€â–º â”‚          â”‚ â”€â”€â”€â–º â”‚          â”‚
     â”‚ Model    â”‚      â”‚ CoT +    â”‚      â”‚ Reaching â”‚      â”‚ Metrics  â”‚
     â”‚ Response â”‚      â”‚ Code     â”‚      â”‚ Defs     â”‚      â”‚ + Report â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚                 â”‚
          â–¼                 â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚<think>   â”‚      â”‚Segments: â”‚      â”‚Def-Use   â”‚      â”‚phantom:  â”‚
    â”‚...       â”‚      â”‚ s1, s2   â”‚      â”‚Graph     â”‚      â”‚ 0.15     â”‚
    â”‚</think>  â”‚      â”‚          â”‚      â”‚          â”‚      â”‚dead:     â”‚
    â”‚```python â”‚      â”‚AST:      â”‚      â”‚Reaching  â”‚      â”‚ 0.33     â”‚
    â”‚def f():  â”‚      â”‚ nodes    â”‚      â”‚Sets      â”‚      â”‚coverage: â”‚
    â”‚  ...     â”‚      â”‚          â”‚      â”‚          â”‚      â”‚ 0.85     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COMPONENT ARCHITECTURE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. COT PARSER                                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Input: Raw model response with <think>...</think> and code blocks     â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  def parse_cot(response: str) -> tuple[list[Segment], AST]: â”‚       â”‚
â”‚  â”‚      # 1. Extract thinking block                             â”‚       â”‚
â”‚  â”‚      think_match = re.search(r'<think>(.*?)</think>', ...)  â”‚       â”‚
â”‚  â”‚                                                               â”‚       â”‚
â”‚  â”‚      # 2. Split into semantic segments                       â”‚       â”‚
â”‚  â”‚      segments = segment_by_sentence(think_text)              â”‚       â”‚
â”‚  â”‚                                                               â”‚       â”‚
â”‚  â”‚      # 3. Extract code block                                  â”‚       â”‚
â”‚  â”‚      code = extract_code_block(response)                     â”‚       â”‚
â”‚  â”‚                                                               â”‚       â”‚
â”‚  â”‚      # 4. Parse code to AST                                   â”‚       â”‚
â”‚  â”‚      ast = parse_python(code)                                â”‚       â”‚
â”‚  â”‚                                                               â”‚       â”‚
â”‚  â”‚      return segments, ast                                    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                         â”‚
â”‚  Output:                                                                â”‚
â”‚  â€¢ segments: List of CoT reasoning steps                               â”‚
â”‚  â€¢ ast: Parsed AST of generated code                                   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONCEPT EXTRACTOR                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  For CoT Segments - Extract "Definitions":                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Segment: "I'll use a hash map for O(1) lookup"             â”‚       â”‚
â”‚  â”‚                                                               â”‚       â”‚
â”‚  â”‚  Extracted Concepts (Definitions):                            â”‚       â”‚
â”‚  â”‚  â€¢ data_structure: "hash_map" / "dict"                       â”‚       â”‚
â”‚  â”‚  â€¢ complexity: "O(1)"                                        â”‚       â”‚
â”‚  â”‚  â€¢ operation: "lookup"                                       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                         â”‚
â”‚  For Code AST - Extract "Uses":                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Code: seen = {}                                             â”‚       â”‚
â”‚  â”‚                                                               â”‚       â”‚
â”‚  â”‚  Extracted Concepts (Uses):                                   â”‚       â”‚
â”‚  â”‚  â€¢ data_structure: "dict"                                    â”‚       â”‚
â”‚  â”‚  â€¢ variable: "seen"                                          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                         â”‚
â”‚  Matching Methods:                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Option A: Keyword matching (simple, fast)                   â”‚       â”‚
â”‚  â”‚  Option B: Embedding similarity (semantic, slower)           â”‚       â”‚
â”‚  â”‚  Option C: LLM-based matching (accurate, expensive)          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. REACHING DEFINITIONS ANALYZER                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Build Def-Use Graph:                                                   â”‚
â”‚                                                                         â”‚
â”‚       CoT Segments (Definitions)          Code Elements (Uses)          â”‚
â”‚       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”‚
â”‚                                                                         â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚       â”‚ s1: hash_map,   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ seen = {}       â”‚          â”‚
â”‚       â”‚     O(1)        â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                         â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚       â”‚ s2: edge_case,  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ if not nums:    â”‚          â”‚
â”‚       â”‚     empty_input â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                         â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚       â”‚ s3: comments    â”‚ â”€â”€â”€â”€â”€â”€X (no edge = DEAD)                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                         â”‚
â”‚                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚           X (no incoming edge) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ return max(...) â”‚ PHANTOM  â”‚
â”‚                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                         â”‚
â”‚  Algorithm:                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  def compute_reaching_defs(segments, ast_nodes):             â”‚       â”‚
â”‚  â”‚      reaching = {}  # node -> set of segments                â”‚       â”‚
â”‚  â”‚      for node in ast_nodes:                                  â”‚       â”‚
â”‚  â”‚          node_concepts = extract_concepts(node)              â”‚       â”‚
â”‚  â”‚          reaching[node] = set()                              â”‚       â”‚
â”‚  â”‚          for seg in segments:                                â”‚       â”‚
â”‚  â”‚              seg_concepts = extract_concepts(seg)            â”‚       â”‚
â”‚  â”‚              if concepts_match(seg_concepts, node_concepts): â”‚       â”‚
â”‚  â”‚                  reaching[node].add(seg)                     â”‚       â”‚
â”‚  â”‚      return reaching                                         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Formal Definitions

### Core Data Structures

```python
from dataclasses import dataclass
from typing import Set, Dict, List
import ast

@dataclass
class Segment:
    """A reasoning step from Chain-of-Thought"""
    id: str                    # Unique identifier (s1, s2, ...)
    text: str                  # Raw text content
    concepts: Set[str]         # Extracted concepts/keywords
    position: int              # Position in CoT sequence

@dataclass  
class CodeElement:
    """An AST node from generated code"""
    id: str                    # Unique identifier (c1, c2, ...)
    node: ast.AST              # Python AST node
    concepts: Set[str]         # Extracted concepts
    line_number: int           # Source location

@dataclass
class ReachingSet:
    """Reaching definitions for a code element"""
    element: CodeElement
    definitions: Set[Segment]  # Segments that "reach" this element
    
    @property
    def is_phantom(self) -> bool:
        """No CoT justification for this code"""
        return len(self.definitions) == 0

@dataclass
class DFAResult:
    """Complete analysis result"""
    segments: List[Segment]
    elements: List[CodeElement]
    reaching: Dict[str, ReachingSet]  # element_id -> reaching set
    
    @property
    def phantoms(self) -> List[CodeElement]:
        """Code elements with no reaching definitions"""
        return [r.element for r in self.reaching.values() if r.is_phantom]
    
    @property
    def dead_segments(self) -> List[Segment]:
        """Segments that don't reach any code"""
        reached = set()
        for rs in self.reaching.values():
            reached.update(s.id for s in rs.definitions)
        return [s for s in self.segments if s.id not in reached]
```

### Formal Analysis Definition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FORMAL DEFINITIONS                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Let:
  S = {sâ‚, sâ‚‚, ..., sâ‚™}     be the set of CoT segments
  C = {câ‚, câ‚‚, ..., câ‚˜}     be the set of code elements
  Îº: S âˆª C â†’ P(Concepts)    be concept extraction function
  â‰ˆ: Concept Ã— Concept â†’ ğ”¹  be concept matching relation

Reaching Definitions:
  RD(cáµ¢) = { sâ±¼ âˆˆ S | âˆƒ concept âˆˆ Îº(cáµ¢) : 
             âˆƒ concept' âˆˆ Îº(sâ±¼) : concept â‰ˆ concept' }

Phantom Set:
  Phantom = { cáµ¢ âˆˆ C | RD(cáµ¢) = âˆ… }

Dead Set:
  Dead = { sâ±¼ âˆˆ S | âˆ€ cáµ¢ âˆˆ C : sâ±¼ âˆ‰ RD(cáµ¢) }

Live Set:
  Live = S \ Dead

```

---

## 5. Metrics

### Primary Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FAITHFULNESS METRICS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHANTOM RATIO                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                    |Phantom|        # code elements without CoT        â”‚
â”‚  phantom_ratio = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚                      |C|              # total code elements            â”‚
â”‚                                                                         â”‚
â”‚  Interpretation:                                                        â”‚
â”‚  â€¢ 0.0 = Perfect: Every code element has CoT justification             â”‚
â”‚  â€¢ 0.5 = Concerning: Half the code "appeared from nowhere"             â”‚
â”‚  â€¢ 1.0 = Complete disconnect: CoT irrelevant to code                   â”‚
â”‚                                                                         â”‚
â”‚  Hypothesis: High phantom_ratio correlates with test failures          â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DEAD RATIO                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                  |Dead|          # CoT steps reaching nothing          â”‚
â”‚  dead_ratio = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚                  |S|               # total CoT segments                 â”‚
â”‚                                                                         â”‚
â”‚  Interpretation:                                                        â”‚
â”‚  â€¢ 0.0 = Efficient: Every reasoning step contributes                   â”‚
â”‚  â€¢ 0.3 = Normal: Some exploratory thinking                             â”‚
â”‚  â€¢ 0.7+ = Suspicious: Mostly filler/padding                            â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REACH COVERAGE                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                      |C \ Phantom|      # justified code elements      â”‚
â”‚  reach_coverage = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                         |C|              # total code elements          â”‚
â”‚                                                                         â”‚
â”‚  Note: reach_coverage = 1 - phantom_ratio                              â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Derived Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DERIVATION DEPTH                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  For each code element c, count the unique segments reaching it:        â”‚
â”‚                                                                         â”‚
â”‚  depth(c) = |RD(c)|                                                     â”‚
â”‚                                                                         â”‚
â”‚  â€¢ depth = 0: Phantom (unjustified)                                    â”‚
â”‚  â€¢ depth = 1: Single justification (common)                            â”‚
â”‚  â€¢ depth > 1: Multiple justifications (well-supported)                 â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REASONING EFFICIENCY                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚                        |Live|                                          â”‚
â”‚  efficiency = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚                |Live| + |Dead|                                          â”‚
â”‚                                                                         â”‚
â”‚  How much of the reasoning was "productive"                            â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Implementation Plan

### Phase 1: Data Collection (2 hours)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: COLLECT COT + CODE SAMPLES                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Model Selection:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model                      Size    CoT Style        Availability      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DeepSeek-Coder-V2-Lite    16B*    Native <think>   HuggingFace       â”‚
â”‚  Qwen2.5-Coder-7B-Instruct 7B      Prompted CoT     HuggingFace       â”‚
â”‚  DeepSeek-R1-Distill-Qwen  7B      Native <think>   HuggingFace       â”‚
â”‚  CodeQwen1.5-7B-Chat       7B      Prompted CoT     HuggingFace       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
* Uses MoE, active params ~2.4B

Dataset:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source: HumanEval or MBPP (with test cases for verification)          â”‚
â”‚  Sample: 50-100 problems                                                â”‚
â”‚  Format: problem â†’ (CoT reasoning, generated code, test results)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 2: Parser Implementation (3 hours)

```python
# cot_parser.py

import re
import ast
from typing import Tuple, List

def parse_response(response: str) -> Tuple[List[str], str]:
    """
    Parse model response into CoT segments and code.
    
    Handles formats:
    - <think>...</think> + ```python...```
    - Reasoning paragraphs + code block
    """
    # Extract thinking block
    think_pattern = r'<think>(.*?)</think>'
    think_match = re.search(think_pattern, response, re.DOTALL)
    
    if think_match:
        cot_text = think_match.group(1)
    else:
        # Fall back to text before code block
        code_start = response.find('```')
        cot_text = response[:code_start] if code_start > 0 else ""
    
    # Extract code block
    code_pattern = r'```(?:python)?\n(.*?)```'
    code_match = re.search(code_pattern, response, re.DOTALL)
    code = code_match.group(1) if code_match else ""
    
    # Segment CoT by sentences
    segments = segment_cot(cot_text)
    
    return segments, code

def segment_cot(text: str) -> List[str]:
    """Split CoT into semantic segments (sentences/steps)."""
    # Split on sentence boundaries
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    
    # Filter empty and very short
    segments = [s.strip() for s in sentences if len(s.strip()) > 10]
    
    return segments

def parse_code_ast(code: str) -> ast.AST:
    """Parse Python code to AST."""
    try:
        return ast.parse(code)
    except SyntaxError:
        # Return empty module for unparseable code
        return ast.Module(body=[], type_ignores=[])
```

### Phase 3: Concept Extraction (4 hours)

```python
# concept_extractor.py

import ast
from typing import Set, Dict
from dataclasses import dataclass

# Concept vocabulary for code patterns
CODE_CONCEPTS = {
    # Data structures
    'dict': {'hash', 'map', 'dictionary', 'hashmap', 'hash map', 'key-value'},
    'list': {'array', 'list', 'sequence', 'collection'},
    'set': {'set', 'unique', 'deduplicate'},
    'stack': {'stack', 'lifo', 'push', 'pop'},
    'queue': {'queue', 'fifo', 'deque'},
    'heap': {'heap', 'priority', 'heapq'},
    'tree': {'tree', 'binary', 'bst', 'trie'},
    'graph': {'graph', 'dfs', 'bfs', 'traverse'},
    
    # Algorithms
    'sort': {'sort', 'order', 'arrange', 'sorted'},
    'search': {'search', 'find', 'lookup', 'binary search'},
    'recursion': {'recursive', 'recursion', 'base case'},
    'dp': {'dynamic programming', 'memoization', 'memo', 'dp'},
    'greedy': {'greedy', 'optimal', 'local'},
    
    # Control flow
    'loop': {'iterate', 'loop', 'for', 'while', 'each'},
    'condition': {'if', 'check', 'condition', 'edge case'},
    'early_return': {'return early', 'base case', 'edge case'},
}

def extract_cot_concepts(segment: str) -> Set[str]:
    """Extract programming concepts from CoT segment."""
    segment_lower = segment.lower()
    concepts = set()
    
    for concept, keywords in CODE_CONCEPTS.items():
        if any(kw in segment_lower for kw in keywords):
            concepts.add(concept)
    
    return concepts

def extract_ast_concepts(node: ast.AST) -> Set[str]:
    """Extract programming concepts from AST node."""
    concepts = set()
    
    # Analyze node type
    if isinstance(node, ast.Dict):
        concepts.add('dict')
    elif isinstance(node, ast.List):
        concepts.add('list')
    elif isinstance(node, ast.Set):
        concepts.add('set')
    elif isinstance(node, ast.For):
        concepts.add('loop')
    elif isinstance(node, ast.While):
        concepts.add('loop')
    elif isinstance(node, ast.If):
        concepts.add('condition')
    elif isinstance(node, ast.Return):
        concepts.add('early_return')
    elif isinstance(node, ast.Call):
        # Check function name
        if isinstance(node.func, ast.Name):
            fname = node.func.id.lower()
            if fname in ('sorted', 'sort'):
                concepts.add('sort')
            elif fname in ('heapify', 'heappush', 'heappop'):
                concepts.add('heap')
    
    return concepts

def get_significant_nodes(tree: ast.AST) -> List[ast.AST]:
    """Get AST nodes worth analyzing (skip trivial ones)."""
    significant = []
    
    for node in ast.walk(tree):
        if isinstance(node, (
            ast.FunctionDef, ast.AsyncFunctionDef,
            ast.For, ast.While, ast.If,
            ast.Dict, ast.List, ast.Set,
            ast.Return, ast.Assign,
            ast.Call
        )):
            significant.append(node)
    
    return significant
```

### Phase 4: Reaching Definitions Analysis (4 hours)

```python
# reaching_defs.py

from dataclasses import dataclass
from typing import Dict, Set, List
import ast

@dataclass
class AnalysisResult:
    reaching: Dict[int, Set[int]]  # node_idx -> set of segment_idx
    phantoms: List[int]            # node indices with no reaching defs
    dead: List[int]                # segment indices not reaching anything
    
    @property
    def phantom_ratio(self) -> float:
        total_nodes = len(self.reaching)
        if total_nodes == 0:
            return 0.0
        return len(self.phantoms) / total_nodes
    
    @property
    def dead_ratio(self) -> float:
        all_segments = set()
        for segs in self.reaching.values():
            all_segments.update(segs)
        total_segments = max(max(all_segments) + 1 if all_segments else 0,
                            len(self.dead) + len(all_segments))
        if total_segments == 0:
            return 0.0
        return len(self.dead) / total_segments

def compute_reaching_definitions(
    cot_segments: List[str],
    code_nodes: List[ast.AST],
    similarity_threshold: float = 0.3
) -> AnalysisResult:
    """
    Compute reaching definitions from CoT segments to code nodes.
    
    A segment s "reaches" a node n if they share concepts.
    """
    # Extract concepts for all segments
    segment_concepts = [extract_cot_concepts(seg) for seg in cot_segments]
    
    # Extract concepts for all nodes
    node_concepts = [extract_ast_concepts(node) for node in code_nodes]
    
    # Compute reaching definitions
    reaching = {}
    for node_idx, node_conc in enumerate(node_concepts):
        reaching[node_idx] = set()
        for seg_idx, seg_conc in enumerate(segment_concepts):
            # Check concept overlap
            if node_conc & seg_conc:  # Non-empty intersection
                reaching[node_idx].add(seg_idx)
    
    # Find phantoms (nodes with no reaching definitions)
    phantoms = [idx for idx, segs in reaching.items() if len(segs) == 0]
    
    # Find dead segments (segments not reaching any node)
    all_reaching = set()
    for segs in reaching.values():
        all_reaching.update(segs)
    dead = [idx for idx in range(len(cot_segments)) if idx not in all_reaching]
    
    return AnalysisResult(reaching, phantoms, dead)
```

### Phase 5: Validation Pipeline (4 hours)

```python
# validation.py

import subprocess
import tempfile
from typing import Tuple, Optional

def execute_code_with_tests(
    code: str, 
    test_code: str,
    timeout: int = 10
) -> Tuple[bool, Optional[str]]:
    """
    Execute generated code against test cases.
    
    Returns: (passed: bool, error_msg: Optional[str])
    """
    full_code = f"{code}\n\n{test_code}"
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write(full_code)
        f.flush()
        
        try:
            result = subprocess.run(
                ['python', f.name],
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            if result.returncode == 0:
                return True, None
            else:
                return False, result.stderr
                
        except subprocess.TimeoutExpired:
            return False, "Timeout"
        except Exception as e:
            return False, str(e)

def analyze_sample(
    problem: str,
    cot_response: str,
    test_code: str
) -> dict:
    """
    Complete analysis pipeline for one sample.
    """
    # 1. Parse response
    segments, code = parse_response(cot_response)
    
    # 2. Parse code AST
    tree = parse_code_ast(code)
    nodes = get_significant_nodes(tree)
    
    # 3. Compute reaching definitions
    result = compute_reaching_definitions(segments, nodes)
    
    # 4. Execute tests
    passed, error = execute_code_with_tests(code, test_code)
    
    return {
        'problem': problem,
        'num_segments': len(segments),
        'num_nodes': len(nodes),
        'phantom_ratio': result.phantom_ratio,
        'dead_ratio': result.dead_ratio,
        'test_passed': passed,
        'error': error,
        'phantoms': result.phantoms,
        'dead': result.dead,
    }
```

### Phase 6: Hypothesis Testing (3 hours)

```python
# hypothesis_test.py

import numpy as np
from scipy import stats
from typing import List, Dict

def test_phantom_correlation(results: List[Dict]) -> Dict:
    """
    Test H1: phantom_ratio correlates with test failure.
    """
    phantom_ratios = [r['phantom_ratio'] for r in results]
    test_passed = [1 if r['test_passed'] else 0 for r in results]
    
    # Point-biserial correlation (continuous vs binary)
    correlation, p_value = stats.pointbiserialr(test_passed, phantom_ratios)
    
    # Group comparison
    passed_phantoms = [r['phantom_ratio'] for r in results if r['test_passed']]
    failed_phantoms = [r['phantom_ratio'] for r in results if not r['test_passed']]
    
    t_stat, t_pvalue = stats.ttest_ind(passed_phantoms, failed_phantoms)
    
    return {
        'correlation': correlation,
        'correlation_p': p_value,
        't_statistic': t_stat,
        't_pvalue': t_pvalue,
        'mean_phantom_passed': np.mean(passed_phantoms) if passed_phantoms else None,
        'mean_phantom_failed': np.mean(failed_phantoms) if failed_phantoms else None,
        'hypothesis_supported': p_value < 0.05 and correlation < 0,
    }

def generate_report(results: List[Dict], hypothesis_results: Dict) -> str:
    """Generate human-readable analysis report."""
    report = []
    report.append("=" * 70)
    report.append("COT-DFA ANALYSIS REPORT")
    report.append("=" * 70)
    
    # Summary statistics
    report.append(f"\nSamples analyzed: {len(results)}")
    report.append(f"Tests passed: {sum(1 for r in results if r['test_passed'])}")
    report.append(f"Tests failed: {sum(1 for r in results if not r['test_passed'])}")
    
    # Metric averages
    report.append(f"\nAverage phantom_ratio: {np.mean([r['phantom_ratio'] for r in results]):.3f}")
    report.append(f"Average dead_ratio: {np.mean([r['dead_ratio'] for r in results]):.3f}")
    
    # Hypothesis test
    report.append("\n" + "-" * 70)
    report.append("HYPOTHESIS TEST: H1 (phantom_ratio predicts failure)")
    report.append("-" * 70)
    
    hr = hypothesis_results
    report.append(f"Correlation: {hr['correlation']:.3f} (p={hr['correlation_p']:.4f})")
    report.append(f"Mean phantom (passed): {hr['mean_phantom_passed']:.3f}")
    report.append(f"Mean phantom (failed): {hr['mean_phantom_failed']:.3f}")
    report.append(f"\nHypothesis supported: {'YES âœ“' if hr['hypothesis_supported'] else 'NO âœ—'}")
    
    return "\n".join(report)
```

---

## 7. Alignment with Neel's Interests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ALIGNMENT WITH NEEL NANDA'S MATS 10.0 INTERESTS               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neel's Interest              â”‚ CoT-DFA Addresses            â”‚ Match    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Can we tell when CoT was    â”‚ Reaching definitions track   â”‚          â”‚
â”‚  causally important for      â”‚ exactly which CoT segments   â”‚    âœ“     â”‚
â”‚  giving its answer?"         â”‚ contribute to code elements  â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Design good monitors or     â”‚ phantom_ratio, dead_ratio,   â”‚          â”‚
â”‚  metrics for whether CoT     â”‚ reach_coverage are exactly   â”‚    âœ“     â”‚
â”‚  is telling us what we       â”‚ this type of metric          â”‚          â”‚
â”‚  think?"                     â”‚                              â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Extend Thought Anchors"     â”‚ Complementary formalism:     â”‚          â”‚
â”‚                              â”‚ â€¢ Thought Anchors: causal    â”‚    âœ“     â”‚
â”‚                              â”‚ â€¢ CoT-DFA: structural        â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Reasoning models"           â”‚ Targets code generation      â”‚          â”‚
â”‚                              â”‚ with native <think> blocks   â”‚    âœ“     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Applied interpretability"   â”‚ Single-pass, no expensive    â”‚          â”‚
â”‚                              â”‚ resampling, actionable       â”‚    âœ“     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "Start simple"               â”‚ Classical compiler analysis  â”‚          â”‚
â”‚                              â”‚ applied to new domain        â”‚    âœ“     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Comparison: CoT-DFA vs Thought Anchors
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  THOUGHT ANCHORS (Bogdan et al.)     COT-DFA (This Work)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚                                                                         â”‚
â”‚  Question: "Which sentences          Question: "Is this a valid        â”‚
â”‚            matter causally?"                    derivation?"            â”‚
â”‚                                                                         â”‚
â”‚  Method:   Counterfactual            Method:   Structural analysis     â”‚
â”‚            perturbation                        (no model calls)        â”‚
â”‚                                                                         â”‚
â”‚  Cost:     O(n) forward passes       Cost:     O(1) - single pass      â”‚
â”‚            per sample                          parse + match           â”‚
â”‚                                                                         â”‚
â”‚  Detects:  â€¢ Important sentences     Detects:  â€¢ Phantom code          â”‚
â”‚            â€¢ Attention patterns                â€¢ Dead reasoning        â”‚
â”‚                                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                         â”‚
â”‚  COMPLEMENTARY: Together they answer both                              â”‚
â”‚  "What matters?" AND "Is it properly derived?"                         â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Extension: Circuit Provenance Bridge

> **If time permits**, extend CoT-DFA to answer:
> "What training data causes unfaithful CoT?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           OPTION C: BRIDGING TO CIRCUIT PROVENANCE                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

REFRAMED RESEARCH QUESTION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Original: "What training data caused this computational pathway?"
     New: "What training data causes UNFAITHFUL CoT?"

NOVEL HYPOTHESIS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
H5: Training examples with shortcuts (correct answer, weak reasoning)
    cause models to produce unfaithful Chain-of-Thought.

METHODOLOGY:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. Get faithful vs unfaithful CoT examples                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                  â”‚
    â”‚    Faithful                    Unfaithful                       â”‚
    â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
    â”‚    phantom_ratio < 0.1         phantom_ratio > 0.4              â”‚
    â”‚    dead_ratio < 0.2            dead_ratio > 0.5                 â”‚
    â”‚    test_passed = True          (may or may not pass)            â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                        â”‚
                        â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 2. Apply influence functions to both categories                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                  â”‚
    â”‚    influence(training_example, output) = âˆ‡Î¸L(z_test)áµ€ Hâ»Â¹ âˆ‡Î¸L(z)â”‚
    â”‚                                                                  â”‚
    â”‚    For each category, find top-10 influential training examples â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                        â”‚
                        â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3. Compare influential examples                                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                  â”‚
    â”‚    Faithful Output           Unfaithful Output                  â”‚
    â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
    â”‚    Training examples         Training examples                  â”‚
    â”‚    with strong reasoning     with SHORTCUTS?                    â”‚
    â”‚    chains                                                       â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PASS/FAIL CRITERION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
H5 supported if:
  shortcut_prevalence(unfaithful_influencers) > 
  shortcut_prevalence(faithful_influencers)

Where shortcut = training example that arrives at correct answer
                 without proper reasoning justification

IMPLEMENTATION NOTES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Uses existing Circuit Provenance JAX infrastructure
â€¢ EK-FAC for efficient influence function computation
â€¢ Target model: Qwen2.5-Coder-7B or similar
â€¢ Training data: Code Alpaca or similar instruction-tuning dataset
```

### Integration Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UNIFIED ANALYSIS ARCHITECTURE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           Model Output
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    CoT-DFA Analysis   â”‚
                    â”‚   (Reaching Defs)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                       â”‚
                    â–¼                       â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Faithful    â”‚       â”‚  Unfaithful   â”‚
           â”‚   (low        â”‚       â”‚  (high        â”‚
           â”‚   phantom)    â”‚       â”‚   phantom)    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Circuit Provenance   â”‚
                   â”‚  (Influence Funcs)    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                       â”‚
                   â–¼                       â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Training    â”‚       â”‚   Training    â”‚
           â”‚   Influencers â”‚       â”‚   Influencers â”‚
           â”‚   (Faithful)  â”‚       â”‚  (Unfaithful) â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚     COMPARE           â”‚
                   â”‚  Do unfaithful trace  â”‚
                   â”‚  back to "shortcut"   â”‚
                   â”‚  training examples?   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Compute & Timeline

### Resource Requirements

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COMPUTE BUDGET                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Hardware: Google Colab Pro (H100 80GB)
Constraint: 20 hours total

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase                      â”‚ Hours    â”‚ GPU Memory  â”‚ Notes             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Data Collection         â”‚ 2        â”‚ ~20GB       â”‚ Model inference   â”‚
â”‚ 2. Parser Implementation   â”‚ 3        â”‚ CPU only    â”‚ Pure Python       â”‚
â”‚ 3. Concept Extraction      â”‚ 4        â”‚ CPU/embedderâ”‚ Optional embedder â”‚
â”‚ 4. Reaching Defs Analysis  â”‚ 4        â”‚ CPU only    â”‚ Graph computation â”‚
â”‚ 5. Validation Pipeline     â”‚ 4        â”‚ CPU only    â”‚ Test execution    â”‚
â”‚ 6. Hypothesis Testing      â”‚ 3        â”‚ CPU only    â”‚ Statistical tests â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL CoT-DFA              â”‚ 20       â”‚             â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EXTENSION (if time permits):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Circuit Provenance      â”‚ 10+      â”‚ ~50GB       â”‚ Influence funcs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Timeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           20-HOUR TIMELINE                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Week 1 (10 hours):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Day 1-2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] Data collection + parser (5h)
         â€¢ Generate CoT samples from coding model
         â€¢ Implement parser for <think> + code blocks
         â€¢ Build basic concept extraction

Day 3-4: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] Reaching definitions core (5h)
         â€¢ Implement matching algorithm
         â€¢ Build def-use graph construction
         â€¢ Calculate metrics

Week 2 (10 hours):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Day 5-6: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] Validation + testing (5h)
         â€¢ Execute generated code against test cases
         â€¢ Collect pass/fail data
         â€¢ Build analysis pipeline

Day 7:   [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] Hypothesis testing + report (5h)
         â€¢ Statistical analysis
         â€¢ Generate visualizations
         â€¢ Write up findings

Extension (if ahead):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Day 8+:  [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Circuit Provenance bridge
         â€¢ Classify outputs by faithfulness
         â€¢ Run influence functions
         â€¢ Compare training influencers
```

---

## 10. Expected Results

### Success Criteria

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PASS/FAIL CRITERIA                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PRIMARY HYPOTHESIS (H1):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PASS: Significant negative correlation (p < 0.05) between 
      phantom_ratio and test pass rate

      Higher phantoms â†’ More failures (as expected)

FAIL: No significant correlation OR positive correlation
      (phantoms don't predict failure)

INTERESTING FAILURE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Even if H1 fails, the tool has value if:
â€¢ We find different phantom patterns for different error types
â€¢ Dead ratio correlates with something else (code quality?)
â€¢ Certain problem types have systematically higher phantoms
```

### Expected Outputs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DELIVERABLES                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. COLAB NOTEBOOK
   â”œâ”€â”€ Cell 1: Setup + model loading
   â”œâ”€â”€ Cell 2: Data collection (generate N samples)
   â”œâ”€â”€ Cell 3: Parser implementation
   â”œâ”€â”€ Cell 4: Concept extractor
   â”œâ”€â”€ Cell 5: Reaching definitions analyzer
   â”œâ”€â”€ Cell 6: Validation pipeline
   â”œâ”€â”€ Cell 7: Hypothesis testing
   â””â”€â”€ Cell 8: Visualizations + report

2. METRICS TABLE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Problem ID   â”‚ phantom_ratioâ”‚ dead_ratio   â”‚ test_passed  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ humaneval_1  â”‚ 0.15         â”‚ 0.33         â”‚ True         â”‚
   â”‚ humaneval_2  â”‚ 0.42         â”‚ 0.18         â”‚ False        â”‚
   â”‚ ...          â”‚ ...          â”‚ ...          â”‚ ...          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. CORRELATION ANALYSIS
   â€¢ Point-biserial correlation coefficient
   â€¢ t-test between passed/failed groups
   â€¢ Effect size (Cohen's d)

4. VISUALIZATIONS
   â€¢ Scatter: phantom_ratio vs pass rate
   â€¢ Box plot: phantom distribution by pass/fail
   â€¢ Heatmap: concept matching matrix
```

---

## Quick Start

```python
# Full pipeline example

from cot_dfa import analyze_sample, test_phantom_correlation

# 1. Collect samples
samples = collect_cot_samples(model="deepseek-r1", n=100)

# 2. Analyze each sample
results = [analyze_sample(s.problem, s.response, s.tests) for s in samples]

# 3. Test hypothesis
hypothesis = test_phantom_correlation(results)

# 4. Generate report
print(generate_report(results, hypothesis))
```

---

## File Structure

```
cot-dfa-mats/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_collection.ipynb
â”‚   â”œâ”€â”€ 02_cot_parser.ipynb
â”‚   â”œâ”€â”€ 03_reaching_defs.ipynb
â”‚   â”œâ”€â”€ 04_validation.ipynb
â”‚   â””â”€â”€ 05_hypothesis_test.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cot_parser.py
â”‚   â”œâ”€â”€ concept_extractor.py
â”‚   â”œâ”€â”€ reaching_defs.py
â”‚   â”œâ”€â”€ validation.py
â”‚   â””â”€â”€ hypothesis_test.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ humaneval/
â”‚   â””â”€â”€ samples/
â””â”€â”€ results/
    â”œâ”€â”€ metrics.csv
    â””â”€â”€ report.md
```

---

## References

1. **Thought Anchors** - Bogdan, Christoph, et al. (2024) - Counterfactual approach
2. **Reaching Definitions** - Aho, Sethi, Ullman - Dragon Book, Ch. 9
3. **CoT Faithfulness** - Anthropic Research - Measuring Faithfulness in CoT

---

## Author

**Shakthi Bachala**  
PhD Candidate, University of Nebraska-Lincoln  
Research: Compiler-Integrated AI Interpretability (IAM)

*Applying decades of program analysis wisdom to the emerging challenge 
of understanding AI reasoning.*